{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc # Garbage collector module for memory management\nfrom matplotlib import pyplot # For data visualization\nfrom matplotlib.image import imread\nimport matplotlib.pyplot as plt\nimport cv2 # OpenCV for image manipulation\nfrom tensorflow import keras # We need keras library\nfrom tqdm import tqdm # To read in images in batches and see progress\nfrom sklearn.model_selection import train_test_split # For the creation of training and validation sets\n# Define model related parameters\nfrom keras import optimizers\nfrom keras.models import Sequential , Model\nfrom keras.layers import Input , Dense , Dropout , Flatten\nfrom keras.layers import Conv2D,MaxPooling2D , BatchNormalization\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint \nfrom keras.preprocessing.image import ImageDataGenerator # Used for Data augmentation\nfrom keras import backend as K # For specialized and optimized tensor manipulation\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading in the training and test csv files\ndf_train_data = pd.read_csv(\"../input/planets-dataset/planet/planet/train_classes.csv\" )\ndf_test_data = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\ndf_train_data.head() # Checking out the first five rows\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separating the 'tags' column of the training dataset into a list\nflatten = lambda l: [item for sublist in l for item in sublist]\nlabels = list (set(flatten([l.split (' ') for l in df_train_data ['tags'].values])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Organizing a label mapping\nlabel_map = {l: i for i, l in enumerate(labels)}\ninv_label_map = {i: l for l, i in label_map.items()}\nlabel_map","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading in the train image dataset\nx_train= []\ny_train= []\nfor img, label in tqdm(df_train_data.values, miniters = 1000):\n  target = np.zeros(17)\n  \n  # We create the 17-dimensional binary label vectors i.e One-hot encoding it\n  for tag in label.split(' '):\n    target[label_map[tag]]=1\n  \n  # Reshaping and assigning to arbitrary variables\n  x_train.append(cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/train-jpg/{}.jpg'.format(img)), (64,64)))\n  y_train.append(target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We Read in the test image dataset and merge the test_additional jpg file to give an output of 61191 rows\nx_test = []\n \nfor img, label in tqdm(df_test_data[0:40669].values, miniters=1000):\n    fil = cv2.resize(cv2.imread('../input/planets-dataset/planet/planet/test-jpg/{}.jpg'.format(img)), (64, 64))\n    x_test.append(fil)\n \nfor img, label in tqdm(df_test_data[40669:].values, miniters=1000):\n    fil = cv2.resize(cv2.imread('../input/planets-dataset/test-jpg-additional/test-jpg-additional/{}.jpg'.format(img)), (64, 64))\n    x_test.append(fil)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change lists to numpy arrays and normalize\nx_train = np.array(x_train, np.float16)/255.\ny_train = np.array(y_train, np.uint8)\nx_test = np.array(x_test, np.float16)/255.\n\n# Splitting the training dataset into training and validation sets\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, shuffle = True, random_state = 1)\n\nprint(x_train.shape, y_train.shape, x_val.shape, y_val.shape)\n# prints  (32383, 64, 64, 3) (32383, 17) (8096, 64, 64, 3) (8096, 17)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 64\ninput_channels = 3\n \n\nmodel = Sequential()\n\n# Input layer\nmodel.add(BatchNormalization(input_shape=(input_size, input_size, input_channels)))\n\n# CCM_1\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n#CCM_2\nmodel.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n \n#CCM_3\nmodel.add(Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n \n#CCM_4\nmodel.add(Conv2D(256, kernel_size=(3, 3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n\n# Create a feature vector from the CCM_4 final layer\nmodel.add(Flatten())\n\n# Fully Connected (FC) Layer\nmodel.add(Dense(512, activation='relu'))\nmodel .add(BatchNormalization())\nmodel.add(Dropout(0.5))\n\n# Output layer\nmodel.add(Dense(17, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining the fbeta metric\ndef fbeta(y_true, y_pred, threshold_shift=0):\n    beta = 2\n \n    # just in case of hipster activation at the final layer\n    y_pred = K.clip(y_pred, 0, 1)\n \n    # shifting the prediction threshold from .5 if needed\n    y_pred_bin = K.round(y_pred + threshold_shift)\n \n    tp = K.sum(K.round(y_true * y_pred_bin)) + K.epsilon()\n    fp = K.sum(K.round(K.clip(y_pred_bin - y_true, 0, 1)))\n    fn = K.sum(K.round(K.clip(y_true - y_pred, 0, 1)))\n \n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n \n    beta_squared = beta ** 2\n    return (beta_squared + 1) * (precision * recall) / (beta_squared * precision + recall + K.epsilon())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.keras as keras\n# Loading the pre-trained VGG16 architecture module\nfrom tensorflow.keras.applications.vgg16 import VGG16\n\n\n\n# Extract the pre-trained architecture\nbase_model = VGG16(input_shape =(input_size,input_size,3),include_top =False,weights ='imagenet')\nbase_model.summary()\n\n# Get the output of the base_model formed above\nx = base_model.output\n# Flatten to obtain a feature vector\nx = Flatten()(x)\n# Connect the feature vector to to the fully connected (FC) layer\nx = Dense (512 , activation ='relu')(x)\n# Form the output label predictions\npredictions = Dense (17 , activation ='sigmoid')(x)\nmodel = Model(inputs= base_model.input,outputs = predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Implementing ImageDataGenerator for data augmentation. This is a very good technique which reduces overfitting as it generates extra images by flipping, zooming e,t.c the images. This makes the model have more images to learn from.\ndatagen = ImageDataGenerator ( horizontal_flip =True ,\nvertical_flip =True ,\nzoom_range =0.2,\nrotation_range =90 ,\nfill_mode ='reflect')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining other parameters\nepochs=20 # An epoch is one complete pass through the training data, We specify 20 here\n\nopt = keras.optimizers.Adam(learning_rate=0.0001) # Defining our Adam optimizer and learning rate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Compiling our model\nmodel.compile(loss='binary_crossentropy',\n              optimizer=opt,\n              metrics=[fbeta])\n\n\ncallbacks = [EarlyStopping(monitor='val_loss',\n                           patience=2,\n                           verbose=0)]\n\n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We fit our model now. The code below fits the model while generating extra images due to the Imagedatagenerator and fitting them on the fly!\nmodel.fit_generator(datagen.flow(x_train,\ny_train,\nbatch_size =24),\nsteps_per_epoch =len(x_train)/32 ,\nvalidation_data = datagen.flow ( x_val,\ny_val,\nbatch_size =24),\nvalidation_steps =len(x_val)/32 ,\nepochs =epochs ,\ncallbacks = callbacks ,\nverbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred =[]\ntest_pred.append (model.predict (x_test , batch_size = 128 , verbose =2) ) # We use the trained model for our test data prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# After prediction, we compile the results in a pandas dataframe form\nresult = np.array (test_pred[0])\nfor i in range (1,len(test_pred) ):\n result += np. array (test_pred)\nresult = pd.DataFrame (result,columns = labels )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = []\nfor i in tqdm(range(result.shape[0]), miniters=1000):\n    a = result.loc[[i]]\n    a = a.apply(lambda x: x > 0.2, axis=1)\n    a = a.transpose()\n    a = a.loc[a[i] == True]\n    ' '.join(list(a.index))\n    preds.append(' '.join(list(a.index)))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving to a csv file called \"my_second_submission\"\ndf_test_data['tags'] = preds\ndf_test_data.to_csv('my_second_submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
